{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Test of the MEG-informed parcellations on MEG experimental datasets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import the required packages\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os.path as op\nimport numpy as np\n\nfrom mne import (read_forward_solution, pick_types_forward,\n                 convert_forward_solution, pick_types,\n                 compute_covariance, find_events, Epochs,\n                 SourceEstimate, extract_label_time_course,\n                 read_labels_from_annot)\nfrom mne.io import read_raw_fif\nfrom mne.datasets import sample\nfrom mne.viz import plot_source_estimates, get_brain_class\n\nimport pickle\n\nimport megicparc\nfrom megicparc.utils import read_dipole_locations, compute_inv_op_rank\nfrom megicparc.viz import plot_flame_labels, plot_flame_centroids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define input parameters for the flame algorithm running in megicperc\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "knn = 30\ngamma = 0.4\ntheta = 0.05\nsensors_meg = 'grad'\nparc = 'aparc'\n\nfolder_fl = op.join('..', 'data', 'data_mne_sample')\nstring_target_file = op.join(folder_fl,\n                        '{:s}_flame_grad_k{:d}_gamma{:1.2f}_theta{:1.2f}.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define input parameters for the flame algorithm running in megicperc\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "depth = None\nmethod = 'dSPM'\ntmin_snr = 0.0\ntmax_snr = 0.15\ntmin_res = 0\ntmax_res = 0.15"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load lead-field matrix and the anatomy-based parcellation\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_path = sample.data_path()\nsubjects_dir = op.join(data_path, 'subjects')\nsubject = 'sample'\nfwd_file = op.join(data_path, 'MEG', subject, 'sample_audvis-meg-eeg-oct-6-fwd.fif')\n\nfwd = read_forward_solution(fwd_file)\nfwd = pick_types_forward(fwd, meg=sensors_meg, eeg=False,\n                         ref_meg=False, exclude='bads')\nfwd = convert_forward_solution(fwd, surf_ori=True, force_fixed=True,\n                               use_cps=True)\n\nlabel_lh = read_labels_from_annot(subject=subject, parc=parc, hemi='lh',\n                       subjects_dir=subjects_dir)\nlabel_rh = read_labels_from_annot(subject=subject, parc=parc, hemi='rh', \n                    subjects_dir=subjects_dir)\nlabel = label_lh + label_rh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load MEG data and estimate noise covariance matrix\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Load raw data\nraw_fname = op.join(data_path, \"MEG\", \"sample\", \n                    \"sample_audvis_filt-0-40_raw.fif\")\n\n# Compute evoked data\n# Ref: https://mne.tools/stable/auto_tutorials/inverse/30_mne_dspm_loreta.html#sphx-glr-auto-tutorials-inverse-30-mne-dspm-loreta-py\nraw = read_raw_fif(raw_fname)  # already has an average reference\nevents = find_events(raw, stim_channel=\"STI 014\")\n\nevent_id = dict(aud_l=1)  \ntmin = -0.2  # start of each epoch (200ms before the trigger)\ntmax = 0.5  # end of each epoch (500ms after the trigger)\nraw.info[\"bads\"] = [\"MEG 2443\", \"EEG 053\"]\nbaseline = (None, 0)  # means from the first instant to t = 0\nreject = dict(grad=4000e-13, mag=4e-12, eog=150e-6)\n\nepochs = Epochs(\n    raw,\n    events,\n    event_id,\n    tmin,\n    tmax,\n    proj=True,\n    picks=(\"meg\", \"eog\"),\n    baseline=baseline,\n    reject=reject,\n)\n\nepochs.apply_baseline((None, 0)) \nevoked = epochs.average()\npicks_inv = pick_types(evoked.info, meg=sensors_meg, exclude='bads') \ny_ev = evoked.data[picks_inv, :]\n\n# Estimate covariance matrix\nnoise_cov = compute_covariance(\n            epochs, tmax=0., method=['empirical'])\nC = noise_cov.data[np.ix_(picks_inv, picks_inv)] / len(epochs)\n\n# Estimate SNR and regularization parameter for the inverse operator\n_, S, V = np.linalg.svd(C)\nlog_ratio_s = np.log(S[0:-1]) - np.log(S[1:])\nrank = np.argmax(log_ratio_s)\nrank = rank + 1\n    \nssv = np.arange(0, rank)\nW = np.dot(np.diag(1/np.sqrt(S[ssv])), V[ssv])\nyW = W.dot(y_ev)\nest_snr = np.sum(yW**2, axis=0) / rank       \nmean_snr = np.mean(est_snr[\n        (evoked.times>=tmin_snr) & (evoked.times <=tmax_snr)])\nlam = 1/mean_snr\n\nprint('***************************************')\nprint('Estimated rank %2d' %rank)\nprint('Estimated snr %2.2f' %mean_snr)\nprint('Estimated lam %2.2f' %lam)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Estimate source activity on the original source-space\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "L = fwd['sol']['data']\nW_inv = compute_inv_op_rank(L, C, lam, \n                depth=depth, method=method, rank=rank)\nx_full = W_inv.dot(y_ev)\n    \n#  Collapse activity on anatomical regions\nstc_aux = SourceEstimate(x_full, \n        [fwd['src'][0]['vertno'], fwd['src'][1]['vertno']], \n        tmin = evoked.times[0], tstep = evoked.times[1]-evoked.times[0], \n        subject = subject)\nx_an_mean = extract_label_time_course(stc_aux, label, \n                        fwd['src'], mode='mean_flip')\n\nx_an_pca = extract_label_time_course(stc_aux, label, \n                        fwd['src'], mode='pca_flip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Estimate source activity on the reduced source-space defined by the \ncentroid of the parcels\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "target_file = string_target_file.format(subject, knn, gamma, theta)\nprint('Loading %s'%target_file)\nwith open(target_file, 'rb') as aux_lf:\n    flame_data = pickle.load(aux_lf)\n    \nnum_roi = flame_data['centroids']\n    \nL_red = fwd['sol']['data'][:, flame_data['centroids_id']]\nW_red = compute_inv_op_rank(L_red, C, lam, \n                depth=depth, method=method, rank=rank)\nx_fl = W_red.dot(y_ev)\n\nprint('***************************************')\nprint('Number of MEG-informed parcels=%d' %num_roi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot source estimated on full source-space\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "vertices_plot = [fwd['src'][0]['vertno'], fwd['src'][1]['vertno']]\nflame_labels = megicparc.store_flame_labels(\n                        flame_data, fwd['src'], subject)\n\nnv_lh = fwd['src'][0]['nuse']\ntimes = evoked.times\naux_t = np.where((times > tmin_res) & (times < tmax_res))[0]\nt_peak_lh = aux_t[np.argmax(np.max(abs(x_full[0:nv_lh, aux_t]), axis=0))]\nt_peak_rh = aux_t[np.argmax(np.max(abs(x_full[nv_lh:, aux_t]), axis=0))]\n\n\nBrain = get_brain_class()\nx_full_norm = np.zeros(x_full.shape[0])\nx_full_norm[0:nv_lh] = abs(x_full[0:nv_lh, t_peak_lh]) \\\n                            / np.max(abs(x_full[0:nv_lh, t_peak_lh]))\nx_full_norm[nv_lh:] = abs(x_full[nv_lh:, t_peak_rh]) \\\n                            / np.max(abs(x_full[nv_lh:, t_peak_rh]))\n\nstc_full = SourceEstimate(x_full_norm[:, np.newaxis], vertices_plot, \n                          tmin = 0, tstep = 1, subject=subject)\n\nbrain = plot_source_estimates(stc_full, subject, surface='inflated', \n            hemi='both', subjects_dir=subjects_dir, background='white', \n            foreground='black', time_label=None, time_viewer=False,\n            clim={'kind' : 'value', 'lims' : [0.1, 0.5, 1]}, size=(650, 650))\nbrain.show_view(azimuth=0, elevation=90)\nbrain.add_text(0.95, 0.13, 'Time = %0.3f s'%times[t_peak_rh], \n               font_size=20, justification='right', color='black')\n    \nbrain2 = plot_source_estimates(stc_full, subject, surface='inflated', \n            hemi='both', subjects_dir=subjects_dir, background='white', \n            foreground='black', time_label=None, time_viewer=False,\n            clim={'kind' : 'value', 'lims' : [0.1, 0.5, 1]}, size=(650, 650))\nbrain2.show_view(azimuth=180, elevation=90,distance=600) \nbrain2.add_text(0.05, 0.13, 'Time = %0.3f s'%times[t_peak_lh], \n               font_size=16, justification='left', color='black')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot Source estimation on the reduces source-space\\\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "nf_lh = np.where(flame_data['centroids_id'] < nv_lh)[0].shape[0]\nt_peak_lh_fl = aux_t[np.argmax(np.max(abs(x_fl[0:nf_lh, aux_t]), axis=0))]\nt_peak_rh_fl = aux_t[np.argmax(np.max(abs(x_fl[nf_lh:, aux_t]), axis=0))]\npeak_fl_lh = np.argmax(abs(x_fl[0:nf_lh, t_peak_lh_fl]), axis=0)\npeak_fl_rh = np.argmax(abs(x_fl[nf_lh:, t_peak_rh_fl]), axis=0) + nf_lh\n\n\nidx_fl = [peak_fl_lh+1, peak_fl_rh+1]\nbrain_fl = Brain(subject, hemi='both', surf='inflated', background='white',\n            subjects_dir=subjects_dir, alpha=1, size=(650, 650))\nplot_flame_labels(idx_fl, flame_labels, fwd['src'], \n            subject, subjects_dir, color = [1, 0.64, 0.], brain=brain_fl)\nplot_flame_centroids(flame_data, fwd['src'], subject, \n            subjects_dir, brain=brain_fl, scale_factor=0.65)\nbrain_fl.show_view(azimuth=0, elevation=90)\nbrain_fl.show_view(azimuth=180, elevation=90)\n\n\"\""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}